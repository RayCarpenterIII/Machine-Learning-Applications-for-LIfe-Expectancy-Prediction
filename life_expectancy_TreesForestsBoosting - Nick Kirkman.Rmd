---
title: "ECON 573 Final Project"
output: html_document
date: "2022-10-31"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
setwd("/Users/nicholaskirkman/Desktop/School/ECON 573/Final Project")
library(ISLR2)
library(splines)
library(gbm)
library(glmnet)
library(randomForest)
library(readr)
library(leaps)
library(MASS)
library(tree)
library(dplyr)
library(pls)
library(haven)
library(kableExtra)


hrs = read_csv('/Users/nicholaskirkman/Desktop/School/ECON 573/Final Project/le_final_final.csv')

hrs = subset(hrs, select = -c(hhidpn,wave,dage_m, id,...1, iwbeg,n2,nt,puff,puffpos,timwlk))

hrs.numeric = subset(hrs, select = c(dage_y,raedyrs,bmi,conde,cogtot,hsptim,hatotb,iearn,isret,logiearn,logisret,loghspti,loghatotb))

hrs.numeric = hrs.numeric %>% mutate_if(is.character,as.numeric)

hrs.factor = subset(hrs, select = -c(dage_y,raedyrs,bmi,conde,cogtot,hsptim,hatotb,iearn,isret,logiearn,logisret,loghspti,loghatotb))

hrs.factor = hrs.factor %>% mutate_if(is.character,as.factor)

hrs = na.omit(cbind(hrs.numeric,hrs.factor))
```



```{r}
set.seed (18)
train <- sample(1: nrow(hrs), nrow (hrs) / 2)
test <- hrs[-train,]
tree.lifespan <- tree(dage_y ~., hrs, subset = train)
summary(tree.lifespan)

plot(tree.lifespan)
text(tree.lifespan, pretty = 0)
```

```{r, warning=FALSE}
cv.lifespan <- cv.tree(tree.lifespan)
plot(cv.lifespan$size , cv.lifespan$dev, type = "b", xlab = "Tree Size", ylab = "Deviance")
```

```{r}
prune.lifespan <- prune.tree(tree.lifespan , best = 5)
plot(prune.lifespan)
text(prune.lifespan , pretty = 0)
```

```{r, warning=FALSE}
yhat <- as.numeric(predict(tree.lifespan, newdata = test))
lifespan.test <- test$dage_y
plot(yhat, lifespan.test)
abline(0, 1)
sqrt(mean((yhat - lifespan.test)^2))

```
```{r}
set.seed(18)

bag.lifespan <- randomForest(dage_y ~., hrs, subset = train, mtry = 43, importance = TRUE)

bag.lifespan
```

```{r}
yhat.bag <- predict(bag.lifespan, newdata = hrs[-train,])
plot(yhat.bag , lifespan.test, xlab = "Bagged Predictions", ylab = "Validation-Set Lifespan",pch=19, col = 'red')
abline (0, 1, col = 'blue', lwd = 3)
sqrt(mean((yhat.bag - lifespan.test)^2))
```

```{r}
set.seed (18)
rf.lifespan <- randomForest(dage_y ~., data = hrs,
subset = train, importance = TRUE)
yhat.rf <- predict (rf.lifespan, newdata = test)
sqrt(mean((yhat.rf - lifespan.test)^2))
```


```{r}
importance(rf.lifespan)
```

```{r}
varImpPlot(rf.lifespan, main = "Variable Importance in Random Forest", n.var = 10)
```

```{r}
set.seed(18)
boost.lifespan <- gbm(dage_y ~., data = hrs[train , ],
distribution = "gaussian", n.trees = 5000,
interaction.depth = 4)

influence = summary(boost.lifespan)
summary(boost.lifespan)
df = data.frame('Variable' = c(influence$var), 'Relative Influence' = c(influence$rel.inf))

df = df[c(1,2,3,4,5),]

df %>%
  kbl() %>%
  kable_classic(full_width = F, html_font = "Cambria")
```

```{r}
plot(boost.lifespan , i = "agey_m", xlab = "Age at Time of Interview", ylab = "Age at Death")
plot(boost.lifespan , i = "cendiv", ylab = "Age at Death", pch  = 19)
```

```{r}
yhat.boost <- predict(boost.lifespan,
newdata = hrs[-train , ], n.trees = 5000)
sqrt(mean((yhat.boost - lifespan.test)^2))
```

```{r}
boost.lifespan <- gbm(dage_y ~., data = hrs[train , ],
distribution = "gaussian", n.trees = 5000,
interaction.depth = 4, shrinkage = 0.2, verbose = F)

yhat.boost <- predict(boost.lifespan ,
                      
newdata = hrs[-train , ], n.trees = 5000)
sqrt(mean((yhat.boost - lifespan.test)^2))
```


```{r}
hrs.numeric.scaled = scale(hrs.numeric)

hrs.scaled = na.omit(cbind(hrs.numeric,hrs.factor))

set.seed(18)
pls.fit <- plsr(dage_y ~., data = hrs.scaled, subset = train,
validation = "CV")
summary(pls.fit)
```


```{r}
validationplot(pls.fit , val.type = "MSEP", main = "", xlab = "Number of Components", ylab = "MSE")

pls.pred <- predict(pls.fit, hrs[-train,], ncomp = 20)
sqrt(mean((pls.pred - lifespan.test)^2))
```

```{r}
df = data.frame('Method' = c("No Model - Mean","Simple OLS","Elastic-Net","SVM Radial Kernel","Simple Decsion Tree","Bagging","Random Forest","Boosting","K-Nearest Neighbors", "Partial Least Squares"), 'Test RMSE' = c(9.37,11.86,7.61, 2.24,4.1,3.41,3.35,3.31,5.45, 3.48))

df %>%
  kbl() %>%
  kable_classic(full_width = F, html_font = "Cambria")
```

